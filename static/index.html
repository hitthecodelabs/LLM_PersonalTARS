<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>TARS Web Assistant</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 2rem; }
    .row { display: flex; gap: 1rem; align-items: center; }
    #micBtn { padding: .8rem 1.2rem; border: 0; border-radius: 10px; background: #111; color: #fff; cursor: pointer; }
    #micBtn.listening { background: #d32f2f; }
    #you, #ai { white-space: pre-wrap; padding: .8rem; border-radius: 8px; }
    #you { background: #f2f2f2; }
    #ai { background: #eef7ff; }
  </style>
</head>
<body>
  <h1>üéôÔ∏è TARS</h1>
  <div class="row">
    <button id="micBtn">Mant√©n pulsado para hablar</button>
    <span id="status">listo</span>
  </div>
  <h3>T√∫</h3>
  <div id="you"></div>
  <h3>TARS</h3>
  <div id="ai"></div>

  <script>
    const API_BASE = "http://localhost:8000"; // c√°mbialo en prod
    let sessionId = localStorage.getItem("sessionId");
    let recognition, recognizing = false;
    let voices = [], esVoice = null;
    let speaking = false;

    // Inicializa sesi√≥n en el backend
    async function ensureSession() {
      if (!sessionId) {
        const r = await fetch(`${API_BASE}/session`);
        const j = await r.json();
        sessionId = j.sessionId;
        localStorage.setItem("sessionId", sessionId);
      }
    }

    // TTS: selecciona una voz en espa√±ol si existe
    function pickVoice() {
      voices = window.speechSynthesis.getVoices();
      esVoice = voices.find(v => v.lang?.toLowerCase().startsWith("es") && /google|microsoft|spanish/i.test(v.name)) ||
               voices.find(v => v.lang?.toLowerCase().startsWith("es")) ||
               null;
    }
    window.speechSynthesis.onvoiceschanged = pickVoice; pickVoice();

    // Hablar (interrumpible)
    function speak(text) {
      if (!text || !window.speechSynthesis) return;
      const u = new SpeechSynthesisUtterance(text);
      u.lang = esVoice?.lang || "es-ES";
      u.voice = esVoice || null;
      u.rate = 1.0; u.pitch = 1.0;
      speaking = true;
      u.onend = () => { speaking = false; };
      speechSynthesis.speak(u);
    }

    // Corta cualquier habla en curso (barge-in)
    function stopSpeaking() {
      if (window.speechSynthesis && speechSynthesis.speaking) {
        speechSynthesis.cancel();
        speaking = false;
      }
    }

    // STT del navegador (Chrome/Edge; Safari m√≥vil limitado; Firefox no)
    function setupSTT() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        document.getElementById('status').textContent = "Tu navegador no soporta reconocimiento de voz. Usa entrada de texto o Cloud STT.";
        return null;
      }
      const r = new SR();
      r.lang = "es-ES";
      r.interimResults = true;
      r.continuous = true;
      r.maxAlternatives = 1;
      return r;
    }
    recognition = setupSTT();

    const micBtn = document.getElementById("micBtn");
    const statusEl = document.getElementById("status");
    const youEl = document.getElementById("you");
    const aiEl = document.getElementById("ai");

    // Mantener pulsado para hablar
    micBtn.addEventListener("mousedown", startListening);
    micBtn.addEventListener("touchstart", (e)=>{ e.preventDefault(); startListening(); }, {passive:false});
    document.addEventListener("mouseup", stopListening);
    document.addEventListener("touchend", stopListening);

    function startListening() {
      if (!recognition) return;
      stopSpeaking(); // barge-in
      if (recognizing) return;
      recognizing = true;
      micBtn.classList.add("listening");
      statusEl.textContent = "escuchando...";
      youEl.textContent = "";
      recognition.start();

      let finalText = "";
      recognition.onresult = (e) => {
        let interim = "";
        for (let i=e.resultIndex; i<e.results.length; i++){
          const res = e.results[i];
          if (res.isFinal) finalText += res[0].transcript + " ";
          else interim += res[0].transcript;
        }
        youEl.textContent = finalText + (interim ? ` (${interim})` : "");
      };

      recognition.onerror = (e) => {
        statusEl.textContent = `error STT: ${e.error}`;
      };
    }

    function stopListening() {
      if (!recognition || !recognizing) return;
      recognizing = false;
      micBtn.classList.remove("listening");
      statusEl.textContent = "pensando...";
      recognition.onend = () => {
        const text = youEl.textContent.replace(/\s+KATEX_INLINE_OPEN.+KATEX_INLINE_CLOSE\s*$/, "").trim();
        if (text) {
          streamAI(text);
        } else {
          statusEl.textContent = "sin entrada";
        }
      };
      recognition.stop();
    }

    // Streaming de respuesta y TTS frase a frase
    async function streamAI(message) {
      await ensureSession();
      aiEl.textContent = "";
      stopSpeaking();

      const res = await fetch(`${API_BASE}/chat/stream`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message, sessionId }),
      });

      // Actualiza session id si backend cre√≥ una nueva
      const sidHeader = res.headers.get("X-Session-Id");
      if (sidHeader && sidHeader !== sessionId) {
        sessionId = sidHeader;
        localStorage.setItem("sessionId", sessionId);
      }

      const reader = res.body.getReader();
      const decoder = new TextDecoder("utf-8");
      let buffer = "";

      const flushSentences = () => {
        // Emite frases completas para TTS
        const parts = buffer.split(/([\.!\?‚Ä¶]+)\s/);
        while (parts.length > 2) {
          const sentence = (parts.shift() + (parts.shift() || "")) || "";
          const clean = sentence.trim();
          if (clean) {
            aiEl.textContent += clean + " ";
            speak(clean);
          }
        }
        buffer = parts.join("");
      };

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        const chunk = decoder.decode(value, { stream: true });
        buffer += chunk;
        flushSentences();
      }
      // Frase final si qued√≥ algo
      const leftover = buffer.trim();
      if (leftover) {
        aiEl.textContent += leftover + " ";
        speak(leftover);
      }
      statusEl.textContent = "listo";
    }

    // Inicio
    ensureSession();
  </script>
</body>
</html>
